<!DOCTYPE html>
<!-- saved from url=(0049)file:///home/habi/Downloads/navx_defense_pdf.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NavX Capstone Defense Q&amp;A Guide</title>
    <style>
        @page {
            size: A4;
            margin: 2cm;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 21cm;
            margin: 0 auto;
            padding: 20px;
            background: white;
        }
        
        h1 {
            color: #1a1a1a;
            border-bottom: 3px solid #007acc;
            padding-bottom: 10px;
            font-size: 28px;
            margin-top: 0;
        }
        
        h2 {
            color: #007acc;
            font-size: 20px;
            margin-top: 30px;
            border-left: 4px solid #007acc;
            padding-left: 15px;
        }
        
        h3 {
            color: #333;
            font-size: 16px;
            margin-top: 20px;
        }
        
        .metadata {
            background: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 25px;
        }
        
        .metadata p {
            margin: 5px 0;
            font-weight: 500;
        }
        
        .question {
            background: #fff3cd;
            padding: 12px;
            border-left: 4px solid #ffc107;
            margin: 15px 0 10px 0;
            font-weight: 600;
        }
        
        .answer {
            background: #e7f3ff;
            padding: 15px;
            border-left: 4px solid #007acc;
            margin: 0 0 20px 0;
        }
        
        .answer strong {
            color: #007acc;
        }
        
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            page-break-inside: avoid;
        }
        
        th {
            background: #007acc;
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: 600;
        }
        
        td {
            padding: 10px;
            border: 1px solid #ddd;
        }
        
        tr:nth-child(even) {
            background: #f9f9f9;
        }
        
        .section-break {
            page-break-before: always;
        }
        
        @media print {
            body {
                padding: 0;
            }
            
            .question, .answer {
                page-break-inside: avoid;
            }
        }
        
        .button-container {
            text-align: center;
            margin: 30px 0;
            padding: 20px;
            background: #f0f0f0;
            border-radius: 8px;
        }
        
        button {
            background: #007acc;
            color: white;
            border: none;
            padding: 15px 40px;
            font-size: 16px;
            border-radius: 5px;
            cursor: pointer;
            font-weight: 600;
            transition: background 0.3s;
        }
        
        button:hover {
            background: #005a9e;
        }
    </style>
</head>
<body>
    <h1>NavX Capstone Defense: Comprehensive Q&amp;A Preparation Guide</h1>
    
    <div class="metadata">
        <p><strong>Project:</strong> NavX (Vehicle AutoRoute Navigator)</p>
        <p><strong>Role:</strong> Engineering &amp; System Architecture</p>
        <p><strong>Status:</strong> Functional Prototype with "Wizard of Oz" Integration</p>
    </div>

    

    <h2>I. Technical &amp; Robotics Questions (Prof. Kabir &amp; Engineering Faculty)</h2>
    <p><em>Focus: Algorithms, Sensor Fusion, and ROS 2 Implementation.</em></p>

    <h3>1. Sensor Fusion &amp; Data Interpretation</h3>
    <div class="question">Q: "You mention 'Sensor Fusion' in your architecture. How exactly are you translating raw sensor data into the abstract concept of 'Road Comfort'?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "We utilize a statistical variance approach on the IMU data. In the <code>road_quality_node.py</code>, we maintain a sliding window of linear acceleration readings. We calculate the variance of vibration (Score = σ²(aₓ) + σ²(aᵧ)). If this variance crosses a specific threshold (0.85), we classify the road segment as 'POOR', which dynamically updates the cost function in the dashboard."
    </div>

    <h3>2. Computer Vision &amp; Edge Computing</h3>
    <div class="question">Q: "You are running YOLOv8 for hazard detection. Is this processed in the Cloud or on the Edge? How do you handle the latency to ensure safety?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "To ensure low latency, we use a Distributed Edge Architecture. The heavy inference (YOLOv8n) runs on the 'Vehicle Computer' (Laptop) acting as an edge gateway, receiving a low-latency MJPEG stream from the Robot. We optimized performance by implementing adaptive frame skipping (processing every 3rd frame) and resizing inputs to 640px, keeping inference time under 50ms."
    </div>

    <h3>3. ROS 2 Middleware</h3>
    <div class="question">Q: "Why did you choose ROS 2 (Humble) over a simple Python script or ROS 1? What specific advantages does it give your navigation stack?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "ROS 2 was chosen for its real-time capabilities and DDS (Data Distribution Service) backbone, which is essential for future V2X integration. It allows us to decouple the hardware drivers (<code>nexius_joy_teleop</code>) from the logic nodes (<code>road_quality_node</code>), making the system modular and crash-resistant. If the vision node fails, the teleoperation node continues to function independently."
    </div>

    <h2 class="section-break">II. Systems Architecture &amp; Scalability (Prof. Pirahandeh)</h2>
    <p><em>Focus: Latency, Cloud Integration, and Modularity.</em></p>

    <h3>4. System Synchronization</h3>
    <div class="question">Q: "You have a Robot, an AI Server, and a Web Dashboard. How do you synchronize these disparate systems without significant lag?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "We implemented an asynchronous WebSocket bridge (<code>detection_server.py</code>). The Python server subscribes to ROS 2 topics (<code>/battery_state</code>, <code>/nav_status</code>) and broadcasts them to the frontend in a single JSON payload. Using <code>asyncio</code>, we handle the video stream and telemetry concurrently, ensuring that a slow network packet doesn't block the vehicle control loop."
    </div>

    <h3>5. Scalability to Fleets</h3>
    <div class="question">Q: "This works for one TurtleBot. How does this architecture scale to a fleet of 1,000 delivery vehicles?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "The architecture is designed to be bandwidth-efficient. We do <strong>not</strong> stream raw video to the cloud. The processing happens locally on the vehicle (Edge), and only lightweight metadata (Risk Scores, GPS coordinates, Battery Status) is sent to the Fleet Dashboard. This keeps cellular data usage minimal regardless of fleet size."
    </div>

    <h2 class="section-break">III. Smart Mobility &amp; V2X (Prof. Hakil Kim &amp; Dr. Choi)</h2>
    <p><em>Focus: Smart City Integration and Physical Implementation.</em></p>

    <h3>6. V2X Interoperability</h3>
    <div class="question">Q: "You claim this is 'V2X Enabled.' However, you are just using a camera. How does this integrate with actual Smart City infrastructure?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "Currently, our system acts as a V2X <em>Data Provider</em>. By analyzing road vibrations via the <code>road_quality_node</code>, every NavX vehicle acts as a sensor that maps pothole locations. This data can be uploaded to the city's ITS (Intelligent Transport System) to schedule repairs, fulfilling the 'Infrastructure Readiness' goal mentioned in the business plan."
    </div>

    <h3>7. Physical Actuation of "Comfort"</h3>
    <div class="question">Q: "The TurtleBot has a rigid suspension. How do you physically execute the 'Comfort Mode' you promised?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "We simulate active suspension through <strong>Velocity Smoothing</strong>. When 'Comfort Mode' is selected on the dashboard, the <code>nexius_joy_teleop</code> node dynamically clamps the maximum linear acceleration and rotational velocity. This reduces 'jerk' (the derivative of acceleration), which is the primary cause of motion sickness and cargo damage."
    </div>

    <h2 class="section-break">IV. The "Gotcha" Questions (Defending the Demo)</h2>
    <p><em>These questions probe the gap between the Business Pitch and the Engineering Prototype.</em></p>

    <h3>8. The "Magic" Path Planning</h3>
    <div class="question">Q: "The dashboard shows the robot recalculating paths around obstacles. Is the robot actually running A* pathfinding in real-time right now?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "For this demonstration, the Dashboard visualizes the <em>calculated</em> optimal path based on our cost function. However, to ensure safety in this crowded demo environment, the final motor control remains 'Human-in-the-Loop' (Teleoperation) with the system providing force-feedback limits based on the selected profile (Speed vs. Safety)."
    </div>

    <h3>9. Reliability &amp; Failsafes</h3>
    <div class="question">Q: "What happens if the Wi-Fi disconnects? Does the robot crash?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "We designed the <code>smart_camera.py</code> and <code>nexius_joy_teleop</code> nodes to run natively on the Raspberry Pi. Even if the dashboard connection is lost, the low-level safety controllers remain active on the hardware, allowing the vehicle to come to a controlled stop or be driven manually."
    </div>

    <h3>10. Battery Management</h3>
    <div class="question">Q: "Computer vision drains battery. How do you manage power consumption?"</div>
    <div class="answer">
        <strong>The Engineer's Answer:</strong> "We implemented an automated power-saving feature in <code>smart_camera.py</code>. The video stream and lighting systems automatically shut down after 12 seconds of zero velocity (detected via <code>/cmd_vel</code>), ensuring we don't waste energy when the vehicle is idling."
    </div>

    <h2 class="section-break">V. Strategic Cheat Sheet: Linking Code to Slides</h2>
    <p>When answering, reference your specific implementation to validate the Business Team's claims:</p>

    <table>
        <thead>
            <tr>
                <th>Business Claim (PPT)</th>
                <th>Your Engineering Proof (Code)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>"Multi-Criteria Routing"</strong></td>
                <td>The 3 Dashboard Buttons (Fastest, Scenic, Comfort) trigger specific velocity clamps in <code>nexius_joy_teleop.py</code>.</td>
            </tr>
            <tr>
                <td><strong>"Real-time Hazard Detection"</strong></td>
                <td><code>detection_server.py</code> running YOLOv8n inference on the video feed.</td>
            </tr>
            <tr>
                <td><strong>"Road Comfort Analysis"</strong></td>
                <td><code>road_quality_node.py</code> calculating variance on <code>/imu</code> data.</td>
            </tr>
            <tr>
                <td><strong>"User-Adaptive Profiles"</strong></td>
                <td>The WebSocket bridge accepting commands like <code>{"command": "SCENIC"}</code> and altering robot behavior dynamically.</td>
            </tr>
            <tr>
                <td><strong>"Energy Efficiency"</strong></td>
                <td>The logic in <code>smart_camera.py</code> that kills the stream when stationary.</td>
            </tr>
        </tbody>
    </table>

    

</body></html>